---
title: "Project 1: K Nearest Neighbors"
author: "Anthony Schroeder"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Report for project 1 on K Nearest Neighbors}
  %\VignetteEngine{knitr::knitr}
  %\usepackage[UTF-8]{inputenc}
  %\VignetteEncoding{UTF-8}
  
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

```

## Introduction
  For this first project we will be creating a K Nearest Neighbor Model that used N fold cross validation to select the optimal number of neighbors to be used on the test set. Cross Validation tells us which set of training data best fits the validation set by attempting to train the model on may different train/test splits and selecting the one that minimizes the validation loss. This will challenge our R coding and C++ coding experience while showing how Machine Learning models can be used for classification problems both binary and regressive. 

**Manhattan distance(L1): **  **$d(i,j)=\sum_{1}^{n}(|X_1-X_2|+|Y_1-Y_2|)$**

**Nearest neighbor prediction function: **
  This Nearest Neighbor Prediction Function is the function that is responsible for taking in a training observations matrix (n_train_observations x n_features) and the test matrix (n_train_observations x n_features) as well as the maximum number of neighbors to try and lastly the training data output vector (n_train_observations).This function is being called by the NNLearnCV function to obtain a matrix of prediction values for the given test data which will be n_test_observations x max_neighbors).
  This function will be using the L1/Manhattan Distance to calculate the lowest error values for the validation set. The L1 distance will calculate sum of the difference between the test matrix and the train matrix for each observation. These distancee are stored into the distance vector that is n_onservation long. We then must sort the distance vector along side an index vector to retain the K value for each distance. 
  We will then loop over each for (K) and sum up all of the distances that were calculated from the L1 Norm. After we sum all the rows we divide by the current fold number and then save that as the prediction for each K. The output will be a list of predictions (max_neighbors x 1) 

**The optimal number of neighbors:  ** 
  The Cross validation functions is what we will impliment in order to select the optimal number of neighbors for the given test set. The NNLearnCV functions will accept the whole train data set (n_observations_ x n_features) and the labels of that data set (n_features x 1). Optionally the we can pass; the max.neighbors to the function as an integer, and that will default to 30, a fold vector that must be [n_features x 1] and when given nothing will automatically generate a vector of the correct size, and lastly an integer that will represent the nummber of folds to be used in the cross validation.
  Firstly, the function will need to check the dimensions of all the input that needs it. The function requires that the number of columns in X.mat is equal to the number of rows in the label vector Y.vec. The Y.vec needs to be the same size as the fold.vec and lastly, the fold.vec will need to have all content checked to make sure it is lower than the max number of folds given as an argument. 
  Secondly, the function will perform cross validation on each of the fold numbers calculating two matrices of mean loss values (max.neighbors x folds). One of them is for the training data set and the other is for the test/validation set. We will be checking if all of the labels in the Y.vec are inbetween 0 and 1 so that we can use the proper loss function in our calculations. For binary classification we will use the 01-loss while for regression we will use the square loss. This function will call the NN1toKmaxPredict function to calculate a matrix of predications and we can use that to create a matrix of loss values. Then the colMeans() are store for the rows of the return matrix.
  This function returns a list of 
  
  **Square Loss**
  $\mathcal{L(w)} = ||\mathcal{w}-\mathcal{y_i}||^2_2
  
  
  **01-Loss**
  $\mathcal{L(w)} = \sum{log[1+e^(\hat{y_i}X^Tw)]}^n_(i=1) 

## Lets Import some general functionality
```{r}
library(NearestNeighbors)
source("R/General.R")
print(getwd())
source("R/knn.R")
source("R/NN1toKmaxPredict.R")
source("R/NNLearnCV.R")
source("R/NNLearnCV_interface.R")
source("tests/testthat/Prep_Libraries.R")
```

## Data set 1: spam
### Code 
Note, i am using some 'Prep' functions i made to make managing the code easier, and more Efficient. 


```{r}
  #
  #--------------------NN1ToKmaxPredict------------------------------------
  Spam<-Prep_Spam()
  print("Linear_Spam_Test: Question/Requrement:1")
  Fold.vec = Random_Folds(Spam$n_Elements,4)
  Fold.n   = 4
  KNNLearnCV.List = KNNLearnCV(Spam$TrainingData, Spam$TrainingLabels, 30, Fold.vec, Fold.n)
  
  barplot(KNNLearnCV.List$TestMeanError.Means,main = "Spam: KNNLearnCV L2 Mean Error",xlab = "KNN Compared",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------

```

### Matrix of loss values
```{r}
#-------------------UntrainedCV-------------------------------------
  Spam_LossMatrix <-rbind(as.double(KNNLearnCV.List$TestMeanError.mat[,1]),as.double(KNNLearnCV.List$TestMeanError.mat[,KNNLearnCV.List$selected.KNN]))
print(as.double(KNNLearnCV.List$train.loss.mat[,1]))
#print(as.double(KNNLearnCV.List$train.loss.mat[,as.integer(KNNLearnCV.List$selected.KNN)]))

  colnames(Spam_LossMatrix)<-c("Fold1","Fold2","Fold3","Fold4")
  rownames(Spam_LossMatrix)<-c("Untrained","Trained")
  barplot(Spam_LossMatrix, xlab = "Iterations", ylab = "Error",main = "Spam_LossMatrix",legend = (rownames(Spam_LossMatrix)),beside = TRUE)
```

### Train/validation loss plot
```{r}
  plot(colMeans(as.matrix(KNNLearnCV.List$TestMeanError.mat)),type="o", col = "blue", xlab = "Iterations", ylab = "Error",main = "")
  lines(colMeans(as.matrix(KNNLearnCV.List$TrainMeanError.mat)),type="o", col = "gray")
  
dot.x <- KNNLearnCV.List$selected.KNN
dot.y <- KNNLearnCV.List$TestMeanError.Means[dot.x]

matpoints(x = dot.x,
          y = dot.y,
          col = 2,
          pch = 19)
  #legend(25,30,c("decay","growth"),col=c("blue","red"),pch=c(15,19), y.intersp=1800)
```

## Data set 2: SAheart
### Code 
```{r}
  #

  #--------------------NN1ToKmaxPredict------------------------------------
  SAheart<-Prep_SAheart()

  print("KNN_SAheart_Tests: Question:1")
  Fold.vec = Random_Folds(SAheart$n_Elements,4)
  Fold.n   = 4
  KNNLearnCV.List = KNNLearnCV(SAheart$TrainingData, SAheart$TrainingLabels, 30, Fold.vec, Fold.n)
  
  barplot(KNNLearnCV.List$TestMeanError.Means,main = "SAheart: KNNLearnCV L2 Mean Error",xlab = "KNN Compared",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------


```
### Matrix of loss values
```{r}
#-------------------UntrainedCV-------------------------------------
  SAheart_LossMatrix <-rbind(as.double(KNNLearnCV.List$TestMeanError.mat[,1]),as.double(KNNLearnCV.List$TestMeanError.mat[,KNNLearnCV.List$selected.KNN]))
print(as.double(KNNLearnCV.List$TestMeanError.mat[,1]))
#print(as.double(KNNLearnCV.List$train.loss.mat[,as.integer(KNNLearnCV.List$selected.KNN)]))

  colnames(SAheart_LossMatrix)<-c("Fold1","Fold2","Fold3","Fold4")
  rownames(SAheart_LossMatrix)<-c("Untrained","Trained")
  barplot(SAheart_LossMatrix, xlab = "Iterations", ylab = "Error",main = "SAheart_LossMatrix",legend = (rownames(SAheart_LossMatrix)),beside = TRUE)
```
### Train/validation loss plot
```{r}
  plot(colMeans(as.matrix(KNNLearnCV.List$TestMeanError.mat)),type="o", col = "blue", xlab = "Iterations", ylab = "Error",main = "")
  lines(colMeans(as.matrix(KNNLearnCV.List$TrainMeanError.mat)),type="o", col = "gray")
  
dot.x <- KNNLearnCV.List$selected.KNN
dot.y <- KNNLearnCV.List$TestMeanError.Means[dot.x]

matpoints(x = dot.x,
          y = dot.y,
          col = 2,
          pch = 19)
 # legend(25,30,c("decay","growth"),col=c("blue","red"),pch=c(15,19), y.intersp=1800)
```


## Data set 3: Zip.train
### Code and itteration loss
```{r}

  
  Ziptrain<-Prep_Ziptrain()
  print("KNN_Ziptrain_Tests: ")
  Fold.vec = Random_Folds(Ziptrain$n_Elements,4)
  Fold.n   = 4
  
  
  
  #--------------------KNNLearnCV------------------------------------
  KNNLearnCV.List = KNNLearnCV(Ziptrain$TrainingData, Ziptrain$TrainingLabels, 30, Fold.vec, Fold.n)
  
  barplot(KNNLearnCV.List$TestMeanError.Means,main = "Ziptrain: KNNLearnCV L2 Mean Error",xlab = "KNN Compared",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------
```

### Matrix of loss values
```{r}
#-------------------UntrainedCV-------------------------------------
  ZipTrain_LossMatrix <-rbind(as.double(KNNLearnCV.List$TestMeanError.mat[,1]),as.double(KNNLearnCV.List$TestMeanError.mat[,KNNLearnCV.List$selected.KNN]))
print(as.double(KNNLearnCV.List$TestMeanError.mat[,1]))
#print(as.double(KNNLearnCV.List$train.loss.mat[,as.integer(KNNLearnCV.List$selected.KNN)]))

  colnames(ZipTrain_LossMatrix)<-c("Fold1","Fold2","Fold3","Fold4")
  rownames(ZipTrain_LossMatrix)<-c("Untrained","Trained")
  barplot(ZipTrain_LossMatrix, xlab = "Iterations", ylab = "Error",main = "",legend = (rownames(ZipTrain_LossMatrix)),beside = TRUE)
```
### Train/validation loss plot
```{r}
  plot(colMeans(as.matrix(KNNLearnCV.List$TestMeanError.mat)),type="o", col = "blue", xlab = "Iterations", ylab = "Error",main = "")
  lines(colMeans(as.matrix(KNNLearnCV.List$TrainMeanError.mat)),type="o", col = "gray")
  #legend(25,30,c("decay","growth"),col=c("blue","red"),pch=c(15,19), y.intersp=1800)
  dot.x <- KNNLearnCV.List$selected.KNN
  dot.y <- KNNLearnCV.List$TestMeanError.Means[dot.x]
  
  matpoints(x = dot.x,
            y = dot.y,
            col = 2,
            pch = 19)
```
  

## Data set 4: prostate
### Code 
```{r}

  #--------------------NN1ToKmaxPredict------------------------------------
  Prostate<-Prep_Prostate()
  print("NN1ToKmax_Prostate_Tests: ")
  Fold.vec = Random_Folds(Prostate$n_Elements,4)
  Fold.n   = 4
  KNNLearnCV.List = KNNLearnCV(Prostate$TrainingData, Prostate$TrainingLabels, 30, Fold.vec, Fold.n)
  
  barplot(KNNLearnCV.List$TestMeanError.Means,main = "Prostate: KNNLearnCV L2 Mean Error",xlab = "KNN Compared",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------

```
### Matrix of loss values
```{r}
#-------------------UntrainedCV-------------------------------------
  Prostate_LossMatrix <-rbind(as.double(KNNLearnCV.List$TestMeanError.mat[,1]),as.double(KNNLearnCV.List$TestMeanError.mat[,KNNLearnCV.List$selected.KNN]))
print(Prostate_LossMatrix)
#print(as.double(KNNLearnCV.List$train.loss.mat[,as.integer(KNNLearnCV.List$selected.KNN)]))

  colnames(Prostate_LossMatrix)<-c("Fold1","Fold2","Fold3","Fold4")
  rownames(Prostate_LossMatrix)<-c("Untrained","Trained")
  barplot(Prostate_LossMatrix, xlab = "Iterations", ylab = "Error",main = "",legend = (rownames(Prostate_LossMatrix)),beside = TRUE)
```

### Train/validation loss plot
```{r}
  plot(colMeans(as.matrix(KNNLearnCV.List$TestMeanError.mat)),type="o", col = "blue", xlab = "Iterations", ylab = "Error",main = "")
  lines(colMeans(as.matrix(KNNLearnCV.List$TrainMeanError.mat)),type="o", col = "gray")
  #legend(25,30,c("decay","growth"),col=c("blue","red"),pch=c(15,19), y.intersp=1800)
  
  dot.x <- KNNLearnCV.List$selected.KNN
  dot.y <- KNNLearnCV.List$TestMeanError.Means[dot.x]

  matpoints(x = dot.x,
            y = dot.y,
            col = 2,
            pch = 19)
```


## Data set 5: ozone
### Code 
```{r}
  #

  #--------------------NN1ToKmaxPredict------------------------------------
  Ozone<-Prep_Ozone()
  print("NN1ToKmax_Ozone_Tests: ")
  Fold.vec = Random_Folds(Ozone$n_Elements,4)
  Fold.n   = 4
  KNNLearnCV.List = KNNLearnCV(Ozone$TrainingData, Ozone$TrainingLabels, 30, Fold.vec, Fold.n)
  
  barplot(KNNLearnCV.List$TestMeanError.Means,main = "Ozone: KNNLearnCV L2 Mean Error",xlab = "KNN Compared",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------



```
### Matrix of loss values
```{r}
#-------------------UntrainedCV-------------------------------------
  Ozone_LossMatrix <-rbind(as.double(KNNLearnCV.List$TestMeanError.mat[,1]),as.double(KNNLearnCV.List$TestMeanError.mat[,KNNLearnCV.List$selected.KNN]))
print(as.double(KNNLearnCV.List$TestMeanError.mat[,1]))
#print(as.double(KNNLearnCV.List$train.loss.mat[,as.integer(KNNLearnCV.List$selected.KNN)]))

  colnames(Ozone_LossMatrix)<-c("Fold1","Fold2","Fold3","Fold4")
  rownames(Ozone_LossMatrix)<-c("Untrained","Trained")
  barplot(Ozone_LossMatrix, xlab = "Iterations", ylab = "Error",main = "",legend = (rownames(Ozone_LossMatrix)),beside = TRUE)
```
### Train/validation loss plot
```{r}
  plot(colMeans(as.matrix(KNNLearnCV.List$TestMeanError.mat)),type="o", col = "blue", xlab = "Iterations", ylab = "Error",main = "")
  lines(colMeans(as.matrix(KNNLearnCV.List$TrainMeanError.mat)),type="o", col = "gray")
  #legend(25,30,c("decay","growth"),col=c("blue","red"),pch=c(15,19), y.intersp=1800)
  
  dot.x <- KNNLearnCV.List$selected.KNN
  dot.y <- KNNLearnCV.List$TestMeanError.Means[dot.x]

  matpoints(x = dot.x,
            y = dot.y,
            col = 2,
            pch = 19)
  
```
