---
title: "Linear Models Report"
author: "Anthony Schroeder,"
date: ""
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}

---


<a id="top"></a>

# Project 2 LM Vignette
### <authors>
#### NAU Febuary 28, 2019

> [Introduction](#intro)
> [Installation](#install)
> [Steps to Run](#qs)
> [Linear Regression](#lin)
> [LMSquareLossIterations](#lin.SqrLoss)
> [LMSquareLossEarlyStoppingCV](#lin.SqrLossCV)
> [LMSquareLossL2](#lin.SqrLossL2)
> [LMSquareLossL2penalties](#lin.SqrLossPen)
> [LMSquareLossL2CV](#lin.SqrLossL2CV)
> [Logistic Regression](#log)
> [LMLogisticLossIterations](#log.LogLoss)
> [LMLogisticLossEarlyStoppingCV](#log.LogLossCV)
> [LMLogLossL2](#log.LogLossL2)
> [LMLogLossL2penalties](#log.LogLossPen)
> [LMLogLossL2CV](#log.LogLossL2CV)
<a id="intro"></a>


## Introduction

The second machine learning project for our class is to create Linear Learning Models using Logistic Loss for binary classification and Square Loss for other classification problems. We have to use what we discussed in class to code the linear regression and cross validation functions in order to minimize the loss. 



## Testing With Data Sets 
we are going to run our code on the following data sets.

## Data set 1: spam
### Matrix of loss values

print out and/or plot the matrix.

comment on difference between NN and baseline.

### Train/validation loss plot

plot the two loss functions.

What is the optimal number of neighbors?


