---
title: "Linear Models Report"
author: "Anthony Schroeder,"
date: ""
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}

---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<a id="top"></a>

# Project 2 LM Vignette
### <authors>
#### NAU March 1, 2019

> [Introduction](#intro)
> [Installation](#install)
> [Steps to Run](#qs)
> [Linear Regression](#lin)
> [LMSquareLossIterations](#lin.SqrLoss)
> [LMSquareLossEarlyStoppingCV](#lin.SqrLossCV)
> [LMSquareLossL2](#lin.SqrLossL2)
> [LMSquareLossL2penalties](#lin.SqrLossPen)
> [LMSquareLossL2CV](#lin.SqrLossL2CV)
> [Logistic Regression](#log)
> [LMLogisticLossIterations](#log.LogLoss)
> [LMLogisticLossEarlyStoppingCV](#log.LogLossCV)
> [LMLogLossL2](#log.LogLossL2)
> [LMLogLossL2penalties](#log.LogLossPen)
> [LMLogLossL2CV](#log.LogLossL2CV)


<a id="intro"></a>
## Introduction
  The second machine learning project for our class is to create Linear Models using different gradient decent algorithms. We have to use what we discussed in class to code the regression and cross validation functions in order to predict the labels of the test data which is based on two things; the weight vector(obtained through regression) and the test data we are given. 
  We will use the cross validation function to select the optimal number of steps in the regression and then perform the linear regression on the training/validation data for all the folds to obtain the result matrix of all functions run on all train/validation splits. We can use the most accurate fold to predict the labels of the test data using $ cbind(1, X.mat) * W.mat$

  Gradient descent will be done using the gerneral form $w^t = w^(t-1) - \alpha\bigtriangledown\mathcal{l(w)}$. 
  
<a id="lin"></a>
## Linear Regression
Linear regression is a linear modeling method that helps to analyse the relationship between a dependant variable and one or more independent variables. In this project we will be using multiple linear regression which will make a vector of predictions based on the relationship observed during gradient decent. We will be calculating our regressions first with the L1 Norm and then the L2 Norm. 
- L1 $$L1 = \stackrel{argmax}{w\epsilon\rm I\!R^p}\sum_{i=1}^n|X_i|$$
- Squared L2 Loss $$\mathcal{L}(w) = \frac{1}{n}||Xw-y||^2_2$$
- Gradient L2 $$\bigtriangledown \mathcal{L}(w) = 2(Xw-y)*X^T$$

<a id="lin.SqrLoss"></a>
## LMSquareLossIterations
This function will take a matrix of training input (n_train x n_features), a vector of labels for the training data vectors (n_train x 1), it will take a scaler value that is the maximum number of iterations in the decent algorithm(scalar > 1), and lastly it will take in a step size which is the size of each step in the gradent descent(scaler > 0). This function will take the matrix of training data and the vector of labels to perform gradient descent on each vector and then create a matrix of weight vectors created from the gradient decent. The function will output th weight matrix by creating a vector for each iteration (n_features+1 x max.iterations). The matrix is larger than the training data so in order to perform matrix multiplication the first element of the weight vectors should be the intercept term. This function will need to minimize the mean loss, not the total loss or eles the gradient decent may not converge. Another method for convergence is to scale the trainign data matrix to a smaller size so the steps of the algorithm will not have to be as large and we will get a much more accurate convergence value. We will compute a scaled input matrix, with a mean of 0 and standard deviation of 1 for each column. This is how we accomplished the matrix normalization.
```{r}
NormalizeMatrix<-function(Matrix)
{
  # ---------- This creates a scaled vector with sd = 1 mean = 0 for each column in matrix-------
  scaled.mat = matrix(nrow = nrow(Matrix),ncol = ncol(Matrix))
  for(col in 1:ncol(Matrix))
  {
    scaled.mat[,col] = (Matrix[,col] - colMeans(Matrix)[col])/sd(Matrix[,col])

  }
  return(as.matrix(scaled.mat))
}
```
Code Block 1

<a id="lin.SqrLossCV"></a>
## LMSquareLossEarlyStoppingCV
This function will accept a matrix of data (n_train x n_features) and a vector of labels for the training data vectors (n_train x 1), as well as a fold vector (n_train x 1) as well as the maximum number of iterations that can be selected as optimal. This function will perform K-fold cross validation on all the train/validation splits to compute the validation loss of each model to determine the optimal number of steps and iterations where steps = max.iterations. Lastly, we will use LMSquareLossIterations(max.iterations=selected.steps) on the whole training data set to output a list with named elements; mean.validation.loss, mean.train.loss.vec, selected.steps, weight.vec, and predict(testX.mat), which will be a function that takes a test features matrix and returns a vector of predictions.

<a id="lin.SqrLossL2"></a>
## LMSquareLossL2
This function uses the L2 Squared Loss and the cost functiin with a penalty to perform the regression and create a simple fitted model. The inputs of the function will be the scaled input matrix (n_train x n_features) and the label vector (n_train x 1). The function will require an inputed penalty value (int > 0) and an optimum threshold value (int > 0) that the regression will aim to achieve. Lastly the function will take in a step size (int > 0) and the initial weigth vector of the matrix. This function assumes that the matrix is already scaled as discussed above. This function's job is to find the optimal weight vector that minimizes the following cost function.
$$\sum_{i=1}^n \mathcal{L}[w^T x_i, y_i] + \lambda||w||^2_2$$, 
Where $\mathcal{L}$ is the square loss.
This function will output a weight vector for a given penalty parameter. 

<a id="lin.SqrLossPen"></a>
## LMSquareLossL2penalties
This function will accept an unscaled matrix (n_train x n_features) that will need to be scaled as described above, as well as the label vector(n_train x 1). The last input that this function requires is a penalty vector that holds decreasing penalty values to try. This function will then loop over the penalty values calling the LMSquareLossL2 function to recieve a scaled optimal weight vector for each penalty. We then need to unscale the vector using the standard deviation of the columns and we will also use warm starting to converge on the optimal much faster. This function outputs a weight matrix (n_features+1 x n_penalties), weight matrix on original scale, that can be used to get predictions via $cbind(1, X.mat) %*% W.mat$

<a id="lin.SqrLossL2CV"></a>
## LMSquareLossL2CV
This function will accept inputs in the form of an input matrix (n_train x n_features) and the usual label vector (n_train x 1). For cross validation we will  need to recieve a fold vector that is size (n_train x 1) and a penalty vector to pass to the LMSquareLossL2penalties to compute the optimal L2 model. This function will use k fold cross validation to perform the modeling on the train/test split and then comput the mean.validation.loss for each fold to find the best fit model. We will be computing a vector of size n_penalties of mean validation loss values. Minimizing the mean validation loss will help us determine the optimal penalty value. Then we will use these optimals to plug back into the LMSquareLossL2penalties function with the whole data set. Lastly, we will output a list with the following named elements; mean.validation.loss, mean.train.loss.vec, penalty.vec, selected.penalty, weight.vec, the weight vector found by using gradient descent with selected.penalty on the whole training data set, and a predict(testX.mat), which is a function that takes a test features matrix and returns a vector of predictions.

**Fromula: ** **$\hat{y} = XW + B$**
Y.hat = data.matrix(TestingData) %*% data.matrix(W.Matrix) + 

**Gradient: ** **${W'} = 2X^T(WX-y)^2$**
Gradient = 2*sum(W.Vector*TrainingData + TrainingLabels)*TrainingLabels

**Bias Gradient: ** **${W'} = 2I^T((WX+IB)-y)^2$**
#Gradient = 2*sum(W.Vector*TrainingData + TrainingLabels)*TrainingLabels




#### Linear L2 equations
**We are Looking for : ** **$\hat{W}^{Lambda} = argmin_{W\in R^{P}}$**

**Regularization Gradient: ** **${W'} = 2X^T(X-y)^2 + 2*(Labmda)*W$**


<a id="log"></a>
## Logistic Regression
Logistic regression is a linear model that can be used to estimate the parameters of a logistic model such as a win/loss or yes/no decision parameter using multiple independent variables. In thins project we will be using the logistic loss to find the log likelyhood of the test data. We will use the probability parameter to determine if the label is a 0 or 1 for a specific observation. The major difference in these two regression models is the  

<a id="log.LogLoss"></a>
## LMLogisticLossIterations

This function will take a matrix of training input (n_train x n_features), a vector of labels for the training data vectors (n_train x 1), it will take a scaler value that is the maximum number of iterations in the decent algorithm(scalar > 1), and lastly it will take in a step size which is the size of each step in the gradent descent(scaler > 0). This function will take the matrix of training data and the vector of labels to perform gradient descent on each vector and then create a matrix of weight vectors created from the gradient decent. The function will output th weight matrix by creating a vector for each iteration (n_features+1 x max.iterations). The matrix is larger than the training data so in order to perform matrix multiplication the first element of the weight vectors should be the intercept term. This function will need to minimize the mean loss, not the total loss or eles the gradient decent may not converge. Another method for convergence is to scale the trainign data matrix to a smaller size so the steps of the algorithm will not have to be as large and we will get a much more accurate convergence value. We will compute a scaled input matrix, with a mean of 0 and standard deviation of 1 for each column. This is how we accomplished the matrix normalization. 
The only major difference will be in the way the gradient decent is calculated. Below is how the logistic regression will be calulating the gradient loss. 

- Binary Loss $$\bigtriangledown\mathcal{L(w)} =\sum_{i=1}^n\frac{exp(-\hat{y}w^Tx_i)}{1+exp(-\hat{y}w^Tx_i)}(-\hat{y}x_i)$$

<a id="log.LogLossCV"></a>
## LMLogisticLossEarlyStoppingCV

This function will accept a matrix of data (n_train x n_features) and a vector of labels for the training data vectors (n_train x 1), as well as a fold vector (n_train x 1) as well as the maximum number of iterations that can be selected as optimal. This function will perform K-fold cross validation on all the train/validation splits to compute the validation loss of each model to determine the optimal number of steps and iterations where steps = max.iterations. Lastly, we will use LMLogisticLossIterations(max.iterations=selected.steps) on the whole training data set to output a list with named elements; mean.validation.loss, mean.train.loss.vec, selected.steps, weight.vec, and predict(testX.mat), which will be a function that takes a test features matrix and returns a vector of predictions.


<a id="log.LogLossL2"></a>
## LMLogLossL2
This function uses the L2 Squared Loss and the cost functiin with a penalty to perform the regression and create a simple fitted model. The inputs of the function will be the scaled input matrix (n_train x n_features) and the label vector (n_train x 1). The function will require an inputed penalty value (int > 0) and an optimum threshold value that the regression will aim to achieve. Lastly the function will take in a step size (int > 0) and the initial weigth vector of the matrix. This function assumes that the matrix is already scaled as discussed above. This function's job is to find the optimal weight vector that minimizes the following cost function.
$$\sum_{i=1}^n \mathcal{L}[w^T x_i, y_i] + \lambda||w||^2_2$$, 
Where $\mathcal{L}$ is the logistic loss.
This function will output a weight vector for a given penalty parameter.

<a id="log.LogLossPen"></a>
## LMLogLossL2penalties
This function will accept an unscaled matrix (n_train x n_features) that will need to be scaled as described above, as well as the label vector(n_train x 1). The last input that this function requires is a penalty vector that holds decreasing penalty values to try. This function will then loop over the penalty values calling the LMLogisticLossL2 function to recieve a scaled optimal weight vector for each penalty. We then need to unscale the vector using the standard deviation of the columns and we will also use warm starting to converge on the optimal much faster. This function outputs a weight matrix (n_features+1 x n_penalties), weight matrix on original scale, that can be used to get predictions via $cbind(1, X.mat) %*% W.mat$

<a id="log.LogLossL2CV"></a>
## LMLogLossL2CV
This function will accept inputs in the form of an input matrix (n_train x n_features) and the usual label vector (n_train x 1). For cross validation we will  need to recieve a fold vector that is size (n_train x 1) and a penalty vector to pass to the LMSquareLossL2penalties to compute the optimal L2 model. This function will use k fold cross validation to perform the modeling on the train/test split and then comput the mean.validation.loss for each fold to find the best fit model. We will be computing a vector of size n_penalties of mean validation loss values. Minimizing the mean validation loss will help us determine the optimal penalty value. Then we will use these optimals to plug back into the LMLogisticLossL2penalties function with the whole data set. Lastly, we will output a list with the following named elements; mean.validation.loss, mean.train.loss.vec, penalty.vec, selected.penalty, weight.vec, the weight vector found by using gradient descent with selected.penalty on the whole training data set, and a predict(testX.mat), which is a function that takes a test features matrix and returns a vector of predictions.

### Logistic equations
#### Logistic Iteration equations
**Fromula: ** **$\hat{y} = 1/(1+e^{XW})+B$**
Y.hat = 1/(1+exp(-TrainingLabels%*% data.matrix(TrainingData) %*% data.matrix(W.Vector)))

**Gradient: ** **${W'} = 1/(1+e^{-yXW})-y$**
Gradient = 2*sum(W.Vector*TrainingData + TrainingLabels)*TrainingLabels

#### Linear L2 equations
**We are Looking for : ** **$\hat{W}^{Lambda} = argmin_{W\in R^{P}}$**

**Regularization Gradient: ** **${W'} = 2X^T(X-y)^2 + 2*(Labmda)*W$**


## Testing With Data Sets 
we are going to run our code on the following data sets for Binary Classification
- ElemStatLearn::spam 2-class [4601, 57] output is last column (spam).
- ElemStatLearn::SAheart 2-class [462, 9] output is last column (chd).
- ElemStatLearn::zip.train: 10-class [7291, 256] output is first column. (ignore classes other than 0 and 1)
And we will be using the following for regression:
- ElemStatLearn::prostate [97 x 8] output is lpsa column, ignore train column.
- ElemStatLearn::ozone [111 x 3] output is first column (ozone).

# How to use the 'ElemStatLearn' Libraries:


How To use this Linear Models Library:
1. Organize your data into:
  a. Training Data:
  Your data should be a matrix with the Column's containing Feature's, and Row's containing the different training Instances 
    
  b.Training Labels:
  Your data should be a single colomn of numerical values, 
    Note: if all labels are (0 or 1)  training will be classified as Binary classification, and be trained accordingly. otherwise, training will be Regressive.




# Tests with 'ElemStatLearn' Libraries:
We will include the library(LinearModel), to have access to the given functionality.

The R script Prep_Libraries.R in the tests/testthat folder contains some simple data manipulation to prep the data to be used for the LinearModel Algorithms.
```{r}
#library(LinearModel)
source("../tests/testthat/Prep_Libraries.R")
```

## Data set 1: spam

### Matrix of loss values ## 4 x 3 matrix of Error results table

Here the matrix of loss values:
(4 points for each data set (2 points each for loss matrix and train/validation loss plot))

```{r}
library(LinearModel)
source("../tests/testthat/Prep_Libraries.R")

# Data set 1: spam
#----------------------Data Initialization-------------------------------
#For a more specific view, just look at the file :("../tests/testthat/Prep_Libraries.R"), to see the data manipulation/ sanitization of each library.
Spam<- Prep_Spam()
#------------------------------------------------------------------------
 
LossMat.fold.n  <- 4
LossMat.fold.vec<-Random_Folds(Spam$n_Elements,LossMat.fold.n)

Data = cbind(Spam$TrainingData ,Spam$TrainingLabels)
#Randomly shuffle the data
Data<-Data[sample(nrow(Data)),]

#Perform folds.n fold cross validation
for(i in 1:(LossMat.fold.n))
{
  testIndexes <- which(LossMat.fold.vec==i,arr.ind=TRUE)
  testData    <- as.matrix(Data[testIndexes, ])
  trainData   <- as.matrix(Data[-testIndexes, ])
  
  #-------------------------LMSquareLossIterations (SLI_Error)--------------
  Scalar.Step = 0.1
  Iterations  = 30
  LMSquareLossIterations.W.Vec <- LMSquareLossIterations(trainData[,1:NCOL(trainData)-1], trainData[,NCOL(trainData)],Iterations,Scalar.Step)
  SLI.WholeError.Vec <-Find_Wmatrix_MeanL2Error(Spam$TrainingData, Spam$TrainingLabels,as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  SLI.TrainError.Vec <-Find_Wmatrix_MeanL2Error(trainData[,1:NCOL(trainData)-1],trainData[,NCOL(trainData)],as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  SLI.TestError.Vec  <-Find_Wmatrix_MeanL2Error(testData[,1:NCOL(testData)-1],testData[,NCOL(testData)],as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  
  #------------------------------------------------------------------------
  #--------------------LMSquareLossEarlyStoppingCV (ES_CV_Error)-----------
   ES_CV_Error.fold.n  <- 4
   ES_CV_Error.fold.vec<-Random_Folds(Spam$n_Elements,ES_CV_Error.fold.n)
  
   ES.List <-LMSquareLossEarlyStoppingCV(trainData[,1:NCOL(trainData)-1], trainData[,NCOL(trainData)],ES_CV_Error.fold.vec,ES_CV_Error.fold.n,Iterations)
   
   DeNormalizedWeights <- ES.List$w.mat
   DeNorm.Error <-Find_Wmatrix_MeanL1Error(Spam$TrainingData, Spam$TrainingLabels,(DeNormalizedWeights),Spam$BinaryClassification)
   barplot(DeNorm.Error,main = "Question 2: LMSquareLossEarlyStoppingCV:Spam",xlab = "Iteration",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------
  #-------------------------LMSquareLossIterations-------------------------
  
  #------------------------------------------------------------------------
  #-------------------------LMSquareLossIterations-------------------------
  
  #------------------------------------------------------------------------
  
}




#-------------------------Matrix of Loss Values--------------------------

#------------------------------------------------------------------------


```

| Test Set  | Early Stoping | L2 Regularized Predictor | Baseline (30 Iterations)(0.1 step)  | 
|:----------|:--------------|:-------------------------|:------------------------------------|
| 1         |               |                          |  0.3963045                          |  
| 2         |               |                          |                                     |  
| 3         |               |                          |                                     |  
| 4         |               |                          |                                     |  
| Avg.      |               |                          |                                     |

comment on difference in accuracy.
The Accuracy inttially improves drametically, but then deviates away from the optimal solution. 

For each data set, compute a 4 x 3 matrix of mean test loss values:
each of the four rows are for a specific test set,
the first column is for the early stopping predictor,
the second column is for the L2 regularized predictor,
the third column is for the baseline/un-informed predictor.





### Train/validation loss plot

plot the two loss functions.


```{r}
#--------------------LMSquareLossIterations------------------------

#-----------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------


#------------------------Train/validation loss plot----------------------

#------------------------------------------------------------------------

```

For each data set, use 4-fold cross-validation to evaluate the prediction accuracy of your code. For each split s=1 to 4, set aside the data in fold s as a test set. Use ___CV to train a model on the other folds (which should be used in your ___CV function as internal train/validation sets/splits), then make a prediction on the test fold s.

For each train/test split, to show that your algorithm is actually learning something non-trivial from the inputs/features, compute a baseline predictor that ignores the inputs/features.
Regression: the mean of the training labels/outputs.
Binary classification: the most frequent class/label/output in the training data.


What are the optimal regularization parameters?



```{r}

```




Make one or more plot(s) or table(s) that compares these test loss values. For each of the five data sets, is early stopping more accurate than L2 regularization? Are the linear models more accurate than the baseline?

for each data set, run ___CV functions on the entire data set, and plot the mean validation loss as a function of the regularization parameter. plot the mean train loss in one color, and the mean validation loss in another color. Plot a point and/or text label to emphasize the regularization parameter selected by minimizing the mean validation loss function.


## Data set 2: 

### Matrix of loss values

Here is an example of how to use the LMSquareLossIterations function:
//Currently having build issues, but code works within R.Studio 
```{r}

# Data set 2: SAheart_Test
#----------------------Data Initialization-------------------------------
SAheart<- Prep_SAheart()
#------------------------------------------------------------------------
  
 
LossMat.fold.n  <- 4
LossMat.fold.vec<-Random_Folds(Spam$n_Elements,LossMat.fold.n)

Data = cbind(Spam$TrainingData ,Spam$TrainingLabels)
#Randomly shuffle the data
Data<-Data[sample(nrow(Data)),]

#Perform folds.n fold cross validation
for(i in 1:(LossMat.fold.n))
{
  testIndexes <- which(LossMat.fold.vec==i,arr.ind=TRUE)
  testData    <- as.matrix(Data[testIndexes, ])
  trainData   <- as.matrix(Data[-testIndexes, ])
  
  #-------------------------LMSquareLossIterations (SLI_Error)--------------
  Scalar.Step = 0.1
  Iterations  = 30
  LMSquareLossIterations.W.Vec <- LMSquareLossIterations(trainData[,1:NCOL(trainData)-1], trainData[,NCOL(trainData)],Iterations,Scalar.Step)
  SLI.WholeError.Vec <-Find_Wmatrix_MeanL2Error(Spam$TrainingData, Spam$TrainingLabels,as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  SLI.TrainError.Vec <-Find_Wmatrix_MeanL2Error(trainData[,1:NCOL(trainData)-1],trainData[,NCOL(trainData)],as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  SLI.TestError.Vec  <-Find_Wmatrix_MeanL2Error(testData[,1:NCOL(testData)-1],testData[,NCOL(testData)],as.matrix(LMSquareLossIterations.W.Vec),Spam$BinaryClassification)
  
  #------------------------------------------------------------------------
  #--------------------LMSquareLossEarlyStoppingCV (ES_CV_Error)-----------
   ES_CV_Error.fold.n  <- 4
   ES_CV_Error.fold.vec<-Random_Folds(Spam$n_Elements,ES_CV_Error.fold.n)
  
   ES.List <-LMSquareLossEarlyStoppingCV(trainData[,1:NCOL(trainData)-1], trainData[,NCOL(trainData)],ES_CV_Error.fold.vec,ES_CV_Error.fold.n,Iterations)
   
   DeNormalizedWeights <- ES.List$w.mat
   DeNorm.Error <-Find_Wmatrix_MeanL1Error(Spam$TrainingData, Spam$TrainingLabels,(DeNormalizedWeights),Spam$BinaryClassification)
   barplot(DeNorm.Error,main = "Question 2: LMSquareLossEarlyStoppingCV:Spam",xlab = "Iteration",ylab = "Error",beside = TRUE)
  #------------------------------------------------------------------------
  #-------------------------LMSquareLossIterations-------------------------
  
  #------------------------------------------------------------------------
  #-------------------------LMSquareLossIterations-------------------------
  
  #------------------------------------------------------------------------
  
}



#-------------------------Matrix of Loss Values--------------------------

#------------------------------------------------------------------------
```
| Test Set  | Early Stoping | L2 Regularized Predictor | Baseline (30 Iterations)(0.1 step)  | 
|:----------|:--------------|:-------------------------|:------------------------------------|
| 1         |               |                          |  0.3963045                          |  
| 2         |               |                          |                                     |  
| 3         |               |                          |                                     |  
| 4         |               |                          |                                     |  
| Avg.      |               |                          |                                     |

comment on difference in accuracy.
The Accuracy inttially improves drametically, but then deviates away from the optimal solution. 

For each data set, compute a 4 x 3 matrix of mean test loss values:
each of the four rows are for a specific test set,
the first column is for the early stopping predictor,
the second column is for the L2 regularized predictor,
the third column is for the baseline/un-informed predictor.

comment on difference in accuracy.
The Accuracy inttially improves drametically, but then deviates away from the optimal solution. 

### Train/validation loss plot

plot the two loss functions.


```{r}
#--------------------LMSquareLossIterations------------------------

#-----------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------
#--------------------LMSquareLossEarlyStoppingCV------------------------

#------------------------------------------------------------------------


#------------------------Train/validation loss plot----------------------

#------------------------------------------------------------------------
```


comment on difference in accuracy.


### Train/validation loss plot

plot the two loss functions.

What are the optimal regularization parameters?

For each data set, use 4-fold cross-validation to evaluate the prediction accuracy of your code. For each split s=1 to 4, set aside the data in fold s as a test set. Use ___CV to train a model on the other folds (which should be used in your ___CV function as internal train/validation sets/splits), then make a prediction on the test fold s.

For each train/test split, to show that your algorithm is actually learning something non-trivial from the inputs/features, compute a baseline predictor that ignores the inputs/features.
Regression: the mean of the training labels/outputs.
Binary classification: the most frequent class/label/output in the training data.

For each data set, compute a 4 x 3 matrix of mean test loss values:
each of the four rows are for a specific test set,
the first column is for the early stopping predictor,
the second column is for the L2 regularized predictor,
the third column is for the baseline/un-informed predictor.

 

## Error results table
| Test Set  | Early Stoping | L2 Regularized Predictor | Baseline (30 Iterations)(0.1 step)  | 
|:----------|:--------------|:-------------------------|:------------------------------------|
| 1         |               |                          |                            |  
| 2         |               |                          |                                     |  
| 3         |               |                          |                                     |  
| 4         |               |                          |                                     |  
| Avg.      |               |                          |                                     |


## Data set 3: 

### Matrix of loss values

Here is an example of how to use the LMSquareLossIterations function:
//Currently having build issues, but code works within R.Studio 
```{r}


```


comment on difference in accuracy.


### Train/validation loss plot

plot the two loss functions.



For each data set, use 4-fold cross-validation to evaluate the prediction accuracy of your code. For each split s=1 to 4, set aside the data in fold s as a test set. Use ___CV to train a model on the other folds (which should be used in your ___CV function as internal train/validation sets/splits), then make a prediction on the test fold s.

For each train/test split, to show that your algorithm is actually learning something non-trivial from the inputs/features, compute a baseline predictor that ignores the inputs/features.
Regression: the mean of the training labels/outputs.
Binary classification: the most frequent class/label/output in the training data.


What are the optimal regularization parameters?

For each data set, compute a 4 x 3 matrix of mean test loss values:
each of the four rows are for a specific test set,
the first column is for the early stopping predictor,
the second column is for the L2 regularized predictor,
the third column is for the baseline/un-informed predictor.


## Error results table
| Test Set  | Early Stoping | L2 Regularized Predictor | Baseline (30 Iterations)(0.1 step)  | 
|:----------|:--------------|:-------------------------|:------------------------------------|
| 1         |               |                          |                            |  
| 2         |               |                          |                                     |  
| 3         |               |                          |                                     |  
| 4         |               |                          |                                     |  
| Avg.      |               |                          |                                     |






# LMSquareLossL2CV Vs binary classification data set
2-6 points extra credit if, in your Rmd report, you also use LMSquareLossL2CV functions on the binary classification data sets, and comment on the difference in accuracy between logistic/square losses. (2 points per data set)


# KNN Vs Linear and Logistic Models
2-10 points extra credit if, in your Rmd report, you also compare against NNLearnCV, and comment on whether or not linear models or nearest neighbors is more accurate (2 points per data set).




