% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LMLinearSquare_Functions.R
\name{LMSquare_Gradient_L2Regularization}
\alias{LMSquare_Gradient_L2Regularization}
\title{LMSquare_Gradient_L2Regularization}
\usage{
LMSquare_Gradient_L2Regularization(TrainingData, TrainingLabels, W.Vector,
  Penalty = 0)
}
\arguments{
\item{TrainingData}{numeric imput feature matrix [n x p]}

\item{TrainingLabels}{numberic input label vector [n]
either all 0/1 for binary classification or other real numbers for regression}

\item{W.Vector}{Weight values representing the Linear funciton [p+1],}

\item{Penalty}{Scalar that is used to control the L2 regularization operation, to turn off just use '0'(Zero)}

\item{StepSize.Scalar}{scalar integer, determines the size of each step.}
}
\value{
returns the gradient of the W.Vector, in respect to the TrainingData, and TrainingLabels

numeric matrix of the weight matrix at each step, from 1 to Iterations.
Returned Matrix is[n_features+1 x max.iterations], where the first element of the weight vector is be the intercept term(AKA Bias).
}
\description{
Makes iterative steps using gradient decent to find a solution to the Linear Models problem
}
\examples{

}
