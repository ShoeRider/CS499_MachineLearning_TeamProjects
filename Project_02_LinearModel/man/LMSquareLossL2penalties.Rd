% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LMLinearSquare_Functions.R
\name{LMSquareLossL2penalties}
\alias{LMSquareLossL2penalties}
\title{LMSquareLossL2penalties}
\usage{
LMSquareLossL2penalties(TrainingData, TrainingLabels, penalty.vec)
}
\arguments{
\item{TrainingData}{numeric imput feature matrix [n x p]}

\item{TrainingLabels}{numberic input label vector [n],
either all 0/1 for binary classification or other real numbers for regression}

\item{penalty.vec}{is a [m] vector with decreasing (non-negative numeric scalar values) penalty values, that control the L2 regularization.}
}
\value{
numeric matrix of the weight matrix at each step, from 1 to Iterations.
Returned Matrix is[n_features+1 x max.iterations], where the first element of the weight vector is be the intercept term(AKA Bias).
}
\description{
Makes iterative steps using gradient decent to find a solution to the Linear Models problem
}
\examples{
## Example: 1 With The Spam DataSet:##

## Example: 2  With The ZipTrain Dataset:##

}
